{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a411f91-fca3-4e99-b4d3-e6a9764bfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d9e9e7-edab-4f41-b9a2-503ca68ec081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male   19                  15                      39\n",
      "1           2    Male   21                  15                      81\n",
      "2           3  Female   20                  16                       6\n",
      "3           4  Female   23                  16                      77\n",
      "4           5  Female   31                  17                      40\n"
     ]
    }
   ],
   "source": [
    "# Load the Mall Customers dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "# Example of the first few rows in the dataset\n",
    "data = load_data('Mall_Customers.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9b00e0-d7e1-414f-a79c-ec6361a65810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
      "0           1    Male   19                  15                      39\n",
      "1           2    Male   21                  15                      81\n",
      "2           3  Female   20                  16                       6\n",
      "3           4  Female   23                  16                      77\n",
      "4           5  Female   31                  17                      40\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaled_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# After loading data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(scaled_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data.head())  # After loading data\n",
    "print(scaled_data)  # After preprocessing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f907990-26cc-4c9f-9d4f-690e2e7e3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing function\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values for numeric columns by filling with the mean\n",
    "    numeric_cols = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "\n",
    "    # Handle missing values for categorical columns (if applicable) using mode\n",
    "    # This part is assuming you might have categorical columns, e.g., 'Gender'\n",
    "    categorical_cols = ['Gender']  # Add any categorical columns here\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "    # Normalize numerical data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c42b7201-041c-45ff-ac36-82f05284ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    print(\"Preprocessing the data...\")  # Debugging line\n",
    "    numeric_cols = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "    categorical_cols = ['Gender']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[numeric_cols])\n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1618b423-8fe7-4b74-8f0d-f94d8fa703b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for K-Means to determine optimal number of clusters\n",
    "def elbow_method(data):\n",
    "    inertia = []  # List to store inertia values (sum of squared distances)\n",
    "    for k in range(1, 11):  # Try different numbers of clusters (1 to 10)\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)  # KMeans model\n",
    "        kmeans.fit(data)  # Fit the model to the data\n",
    "        inertia.append(kmeans.inertia_)  # Inertia is the sum of squared distances from points to their cluster centers\n",
    "    \n",
    "    # Plot the Elbow curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, 11), inertia, marker='o')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "#This function calculates and plots the inertia for different values of k (number of clusters). The optimal number of clusters corresponds to the \"elbow\" point on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca3f9f4e-093c-40eb-8edd-3ed525dbb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Score for determining cluster quality\n",
    "def silhouette_analysis(data):\n",
    "    scores = []  # List to store silhouette scores\n",
    "    for k in range(2, 11):  # Try different numbers of clusters (2 to 10)\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)  # KMeans model\n",
    "        kmeans.fit(data)  # Fit the model to the data\n",
    "        score = silhouette_score(data, kmeans.labels_)  # Calculate silhouette score\n",
    "        scores.append(score)  # Append the score\n",
    "    \n",
    "    # Plot the Silhouette scores\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(2, 11), scores, marker='o')\n",
    "    plt.title('Silhouette Score for K-Means')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "#This function calculates the silhouette score for different values of k. The silhouette score measures how well each point is clustered and ranges from -1 to 1. A higher score means better clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "424abfbf-2b6d-4279-b6a5-ca293affc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans(self):\n",
    "    print(\"Performing KMeans...\")  # Check if the method is being called\n",
    "    if not self.filepath:\n",
    "        messagebox.showwarning(\"Error\", \"Please upload a dataset first!\")\n",
    "        return\n",
    "    \n",
    "    data = load_data(self.filepath)\n",
    "    scaled_data = preprocess_data(data)\n",
    "\n",
    "    # Perform KMeans\n",
    "    print(\"KMeans in progress...\")  # Check if KMeans is running\n",
    "    elbow_method(scaled_data)\n",
    "    silhouette_analysis(scaled_data)\n",
    "    labels, model = apply_kmeans(scaled_data, 5)\n",
    "\n",
    "    plot_kmeans_2d(scaled_data, labels)\n",
    "    self.result_label.config(text=\"KMeans Clusters Created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9015c40e-1231-4e81-aa5a-0f77fbb02765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans(self):\n",
    "    if not self.filepath:\n",
    "        messagebox.showwarning(\"Error\", \"Please upload a dataset first!\")\n",
    "        return\n",
    "     \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")  # Debugging line\n",
    "    data = load_data(self.filepath)\n",
    "    scaled_data = preprocess_data(data)\n",
    "\n",
    "    # Elbow method to determine optimal clusters\n",
    "    print(\"Performing Elbow Method...\")  # Debugging line\n",
    "    elbow_method(scaled_data)\n",
    "     \n",
    "    # Silhouette analysis to check for cluster quality\n",
    "    print(\"Performing Silhouette Analysis...\")  # Debugging line\n",
    "    silhouette_analysis(scaled_data)\n",
    "     \n",
    "    # Apply KMeans (using a predefined number of clusters, e.g., 5)\n",
    "    print(f\"Performing KMeans with {self.n_clusters} clusters...\")  # Debugging line\n",
    "    labels, model = apply_kmeans(scaled_data, self.n_clusters)\n",
    "\n",
    "    # Visualize clusters in 2D\n",
    "    plot_kmeans_2d(scaled_data, labels)\n",
    "    self.result_label.config(text=f\"KMeans Clusters Created with {self.n_clusters} clusters.\")\n",
    "\n",
    "def perform_dbscan(self):\n",
    "    if not self.filepath:\n",
    "        messagebox.showwarning(\"Error\", \"Please upload a dataset first!\")\n",
    "        return\n",
    "     \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")  # Debugging line\n",
    "    data = load_data(self.filepath)\n",
    "    scaled_data = preprocess_data(data)\n",
    "\n",
    "    # Apply DBSCAN\n",
    "    print(\"Performing DBSCAN...\")  # Debugging line\n",
    "    labels_dbscan = apply_dbscan(scaled_data)\n",
    "\n",
    "    # Visualize DBSCAN results in 2D\n",
    "    plot_dbscan_2d(scaled_data, labels_dbscan)\n",
    "    self.result_label.config(text=\"DBSCAN Clusters Created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2149d169-a43e-4ec6-ac4e-69aebba66554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform DBSCAN clustering\n",
    "def apply_dbscan(data, eps=0.5, min_samples=5):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)  # Initialize DBSCAN model\n",
    "    labels_dbscan = dbscan.fit_predict(data)  # Apply DBSCAN and get cluster labels\n",
    "    return labels_dbscan\n",
    "#DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is an algorithm that groups together points that are closely packed, marking as outliers the points that lie alone in low-density regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f1f64cc-6387-4644-a79b-3a6922a966c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans_2d(data, labels):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(pca_data[:, 0], pca_data[:, 1], c=labels, cmap='viridis', s=50)\n",
    "    plt.title('KMeans Clusters (2D)')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()  # Ensure this is called\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30e6fba5-0a21-423b-9df5-4c24ef07b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize DBSCAN clusters in 2D\n",
    "def plot_dbscan_2d(data, labels):\n",
    "    pca = PCA(n_components=2)  # Use PCA for dimensionality reduction (to 2D)\n",
    "    pca_data = pca.fit_transform(data)  # Reduce dimensions of the data to 2D\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(pca_data[:, 0], pca_data[:, 1], c=labels, cmap='plasma', s=50)  # Scatter plot of clusters\n",
    "    plt.title('DBSCAN Clusters (2D)')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()\n",
    "#The DBSCAN clusters are visualized in 2D similarly using PCA for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d664da2-f984-499b-a173-2a7db803e3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44329b-262d-4768-ab72-162105ebbd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da231330-a70e-41a4-b77d-46f9567b6021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2181f2-a36e-43f7-9a8d-ef46b4093003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9eafee-133b-47de-a043-e4d7fb1fe402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c2580-7789-4a93-bdaf-fc38f03868c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
